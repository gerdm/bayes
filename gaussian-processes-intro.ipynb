{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c4caf4f-9f76-40a6-8d73-fd1d6ef15c6f",
   "metadata": {},
   "source": [
    "# Bayesian-free Gaussian processes\n",
    "\n",
    "Collection of datasets taken from https://www.sfu.ca/~ssurjano/optimization.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7c1240-7553-4faa-bf1a-126327babe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import seaborn as sns\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af115b63-ff12-4b70-9af3-2fc231036332",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.spines.right\"] = False\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"figure.figsize\"] = (7.2, 4.0)\n",
    "\n",
    "sns.set_palette(\"colorblind\")\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "%config InlineBackend.figure_format = \"retina\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a76ea8f-ae81-452c-aa25-586fe278b4a3",
   "metadata": {},
   "source": [
    "## The noisless case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9077a916-6dd4-4c77-940c-c77c4faabaef",
   "metadata": {},
   "source": [
    "Let $Y: {\\cal X} \\to \\mathbb{R}$ be a random variable\n",
    "such that, for any $x_i, x_j \\in {\\cal X}$,\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\mathbb{E}[Y(x_i)] &= 0\\\\\n",
    "    {\\rm Cov}(Y(x_i),Y(x_j)) = \\mathbb{E}[Y(x_i)\\,Y(x_j)] &= k(x_i\\,x_j)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $k:\\mathbb{R}^m\\times\\mathbb{R}^m\\to\\mathbb{R}$ is a valid *kernel function*.\n",
    "\n",
    "## Problem statement\n",
    "Suppose we are given members of the sample space \n",
    "and $\\{x_1, \\ldots, x_t, x_{t+1}, x_{t+j}\\} \\subseteq {\\cal X} \\subseteq {\\mathbb R}^m$.\n",
    "Our goal is to find the best linear unbiased predictor (BLUP) for the random variables $Y_{t+1:t+j}$\n",
    "given the subset of measurements $Y_{1:t}$.\n",
    "\n",
    "That is, we seek a matrix ${\\bf A}^* \\in {\\mathbb R}^{j\\times t}$ such that\n",
    "$$\n",
    "    {\\bf A}^* = \\arg\\min_{{\\bf A}}\\mathbb{E}[\\|Y_{t+1:t+j} - {\\bf A}\\,Y_{1:t}\\|^2_2]\n",
    "$$\n",
    "\n",
    "This takes the form\n",
    "\n",
    "$$\n",
    "    {\\bf A}^* = {\\rm Cov}(Y_{t+1,t+j},Y_{1:T})\\,{\\rm Var}(Y_{1:t})^{-1}\n",
    "$$\n",
    "\n",
    "As a consequence, the best linear unbiased predictor and the error variance-covariance matrix take the form\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\hat{Y}_{t+1:t+j} = {\\bf A}^*\\,Y_{1:t}\n",
    "    &= {\\rm Cov}(Y_{t+1,t+j},Y_{1:T})\\,{\\rm Var}(Y_{1:t})^{-1}\\,Y_{1:T}\\\\\n",
    "    {\\rm Var}(Y_{t+1:t+j} - \\hat{Y}_{t+1:t+j}) &= {\\rm Var}(Y_{t+1:t+j}) - {\\bf A}^*\\,{\\rm Var}(Y_{1:t})\\,{\\bf A}^{*\\intercal}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79990603-ec48-4aca-b579-69def1ffac8f",
   "metadata": {},
   "source": [
    "Because we assume knowledge of the covariance between any two elements of the sample space ${\\cal X}$,\n",
    "it follows that the GP prediction is completely determined by its kernel function $k$ and sampled values for $Y_{1:t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3beb640c-3ba3-4f0e-8fb3-d610b5f431c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_multivariate_gauss(key, mean, cov, n_samples, min=1e-7):\n",
    "    dim = cov.shape[0]\n",
    "    cov = (cov + cov.T) / 2\n",
    "    ev = jnp.linalg.eigh(cov)\n",
    "    cov = ev.eigenvectors @ jnp.diag(jnp.clip(ev.eigenvalues, min=1e-7)) @ jnp.linalg.inv(ev.eigenvectors)\n",
    "    L = jnp.linalg.cholesky(cov)\n",
    "    rvs = jax.random.normal(key, shape=(dim, n_samples))\n",
    "    return (L @ rvs) + mean[:, None]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026f35e5-d1e4-4c7a-bad7-284b8d935c38",
   "metadata": {},
   "source": [
    "### Example: a Gasussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbcbeea9-4735-4a9c-88f1-de70d3244652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kgauss(u, v, sigma2=1.0):\n",
    "    return jnp.exp(-(u[:, None] - v[None, :]) ** 2 / (2 * sigma2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b598b-d967-4014-9393-a4da381e4f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(314)\n",
    "key_x, key_sample = jax.random.split(key)\n",
    "\n",
    "n = 1000\n",
    "x = jax.random.uniform(key=key_x, minval=-1, maxval=1, shape=(n,)).sort()[:, None]\n",
    "x = jnp.linspace(-1, 1, n)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(4, 1, sharex=True, figsize=(6.4, 4.8), sharey=True)\n",
    "n_samples = 5\n",
    "\n",
    "sigma2 = 1.0\n",
    "reg = 1e-7\n",
    "mean = jnp.zeros(n)\n",
    "\n",
    "sigma2_vals = jnp.array([0.001, 0.01, 0.1, 1.0])\n",
    "for ax, sigma2 in zip(axs, sigma2_vals):\n",
    "    cov = kgauss(x, x, sigma2)\n",
    "    sample = sample_multivariate_gauss(key_sample, mean, cov, n_samples)\n",
    "    ax.plot(x, sample)\n",
    "    ax.set_ylabel(rf\"$\\sigma^2={sigma2}$\", fontsize=10)\n",
    "    ax.axhline(y=0, c=\"black\", linestyle=\"--\")\n",
    "    ax.set_xlim(-1, 1)\n",
    "    ax.grid(alpha=0.3)\n",
    "ax.set_xlabel(r\"Sample space ${\\cal X}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c28c83-7c3e-45ed-9a69-e20554c6560e",
   "metadata": {},
   "source": [
    "## BLUP (posterior predictive) estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b1cb16-00df-44f9-8b6d-a86df4064fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = jnp.linspace(0, 1.3, 100)\n",
    "mu_prior = jnp.zeros_like(xtest)\n",
    "sigma = 0.01\n",
    "n_samples = 10\n",
    "x = jnp.array([0.1, 0.2, 0.25, 0.8, 0.9])\n",
    "y = jnp.array([1.3, 1.1, 0.9, 0.85, 0.6])\n",
    "\n",
    "var_train = kgauss(x, x, sigma)\n",
    "cov_test_train = kgauss(xtest, x, sigma)\n",
    "var_test = kgauss(xtest, xtest, sigma)\n",
    "\n",
    "# cov_test_train @ inv(var_train)\n",
    "A_blup = jnp.linalg.solve(var_train, cov_test_train.T).T\n",
    "mu_post = A_blup @ y\n",
    "sigma_post = var_test - A_blup @ var_train @ A_blup.T\n",
    "\n",
    "posterior_sample = sample_multivariate_gauss(key, mu_post, sigma_post, n_samples=n_samples)\n",
    "prior_sample = sample_multivariate_gauss(key, mu_prior, var_test, n_samples=n_samples)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 3), sharey=True)\n",
    "\n",
    "ax[0].plot(xtest, prior_sample, alpha=0.5, c=\"tab:gray\");\n",
    "ax[0].set_title(\"Prior Samples\", fontsize=15)\n",
    "ax[0].plot(xtest, mu_prior, c=\"crimson\", linewidth=2)\n",
    "\n",
    "ax[1].plot(xtest, posterior_sample, alpha=0.5, c=\"tab:gray\");\n",
    "ax[1].plot(xtest, mu_post, c=\"crimson\", linewidth=2)\n",
    "ax[1].scatter(x, y, marker=\"o\", c=\"black\", zorder=5)\n",
    "ax[1].set_title(\"Posterior Samples\", fontsize=15)\n",
    "for axi in ax:\n",
    "    axi.grid(alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a1e5a9-5832-471d-b170-ec0f5d502493",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_bound = mu_post.ravel() + 2 * jnp.diag(sigma_post)\n",
    "lower_bound = mu_post.ravel() - 2 * jnp.diag(sigma_post)\n",
    "\n",
    "plt.plot(xtest, posterior_sample, alpha=0.8, c=\"tab:gray\");\n",
    "plt.plot(xtest, mu_post, c=\"crimson\", linewidth=2)\n",
    "plt.scatter(x, y, marker=\"o\", c=\"black\", zorder=5)\n",
    "plt.fill_between(xtest, lower_bound, upper_bound, color=\"#ccc6\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlabel(r\"Sample space ${\\cal X}$\")\n",
    "plt.ylabel(r\"Observation space $Y(X_j)$\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
